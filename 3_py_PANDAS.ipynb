{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series -> data contained in one column\n",
    "DataFrame -> data contained in ,multiple columns (2d data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age  Salary\n",
      "0   john   24   50000\n",
      "1  peter   25   45000\n",
      "2   lisa   26   60000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\"Name\":[\"john\",\"peter\",\"lisa\"],\n",
    "        \"Age\":[24,25,26],\n",
    "        \"Salary\":[50000,45000,60000]}\n",
    "df=pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year Industry_aggregation_NZSIOC Industry_code_NZSIOC  \\\n",
      "0      2023                     Level 1                99999   \n",
      "1      2023                     Level 1                99999   \n",
      "2      2023                     Level 1                99999   \n",
      "3      2023                     Level 1                99999   \n",
      "4      2023                     Level 1                99999   \n",
      "...     ...                         ...                  ...   \n",
      "50980  2013                     Level 3                 ZZ11   \n",
      "50981  2013                     Level 3                 ZZ11   \n",
      "50982  2013                     Level 3                 ZZ11   \n",
      "50983  2013                     Level 3                 ZZ11   \n",
      "50984  2013                     Level 3                 ZZ11   \n",
      "\n",
      "             Industry_name_NZSIOC               Units Variable_code  \\\n",
      "0                  All industries  Dollars (millions)           H01   \n",
      "1                  All industries  Dollars (millions)           H04   \n",
      "2                  All industries  Dollars (millions)           H05   \n",
      "3                  All industries  Dollars (millions)           H07   \n",
      "4                  All industries  Dollars (millions)           H08   \n",
      "...                           ...                 ...           ...   \n",
      "50980  Food product manufacturing          Percentage           H37   \n",
      "50981  Food product manufacturing          Percentage           H38   \n",
      "50982  Food product manufacturing          Percentage           H39   \n",
      "50983  Food product manufacturing          Percentage           H40   \n",
      "50984  Food product manufacturing          Percentage           H41   \n",
      "\n",
      "                                         Variable_name      Variable_category  \\\n",
      "0                                         Total income  Financial performance   \n",
      "1      Sales, government funding, grants and subsidies  Financial performance   \n",
      "2                    Interest, dividends and donations  Financial performance   \n",
      "3                                 Non-operating income  Financial performance   \n",
      "4                                    Total expenditure  Financial performance   \n",
      "...                                                ...                    ...   \n",
      "50980                                      Quick ratio       Financial ratios   \n",
      "50981              Margin on sales of goods for resale       Financial ratios   \n",
      "50982                                 Return on equity       Financial ratios   \n",
      "50983                           Return on total assets       Financial ratios   \n",
      "50984                            Liabilities structure       Financial ratios   \n",
      "\n",
      "        Value                             Industry_code_ANZSIC06  \n",
      "0      930995  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "1      821630  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "2       84354  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "3       25010  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "4      832964  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "...       ...                                                ...  \n",
      "50980      52  ANZSIC06 groups C111, C112, C113, C114, C115, ...  \n",
      "50981      40  ANZSIC06 groups C111, C112, C113, C114, C115, ...  \n",
      "50982      12  ANZSIC06 groups C111, C112, C113, C114, C115, ...  \n",
      "50983       5  ANZSIC06 groups C111, C112, C113, C114, C115, ...  \n",
      "50984      46  ANZSIC06 groups C111, C112, C113, C114, C115, ...  \n",
      "\n",
      "[50985 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"annual.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:/DSA_ML/test.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7780\\353596319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"E:/DSA_ML/test.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 ext = inspect_excel_format(\n\u001b[1;32m-> 1192\u001b[1;33m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1193\u001b[0m                 )\n\u001b[0;32m   1194\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m     with get_handle(\n\u001b[1;32m-> 1071\u001b[1;33m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     ) as handle:\n\u001b[0;32m   1073\u001b[0m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/DSA_ML/test.xlsx'"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\"E:/DSA_ML/test.xlsx\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring Data in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID          Full Name             Job Title       Department  \\\n",
      "990  E01578       Anthony Hong            Sr. Manger               IT   \n",
      "991  E03430        Leo Herrera  Sr. Business Partner  Human Resources   \n",
      "992  E03058      Robert Wright   Technical Architect               IT   \n",
      "993  E04762  Audrey Richardson              Director               IT   \n",
      "994  E01148     Scarlett Kumar       Systems Analyst               IT   \n",
      "995  E03094       Wesley Young           Sr. Analyst        Marketing   \n",
      "996  E01909       Lillian Khan               Analyst          Finance   \n",
      "997  E04398        Oliver Yang              Director        Marketing   \n",
      "998  E02521        Lily Nguyen           Sr. Analyst          Finance   \n",
      "999  E03545        Sofia Cheng        Vice President       Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "990  Research & Development    Male      Asian   37 2010-11-29         146961   \n",
      "991  Research & Development    Male     Latino   48 1998-04-22          85369   \n",
      "992           Manufacturing    Male  Caucasian   30 2015-06-14          67489   \n",
      "993           Manufacturing  Female  Caucasian   46 2018-10-06         166259   \n",
      "994               Corporate  Female      Asian   55 2009-01-07          47032   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country      City  Exit Date  \n",
      "990     0.11  United States  Columbus        NaT  \n",
      "991     0.00         Brazil    Manaus 2004-11-27  \n",
      "992     0.00  United States   Chicago        NaT  \n",
      "993     0.17  United States   Chicago        NaT  \n",
      "994     0.00  United States  Columbus        NaT  \n",
      "995     0.00  United States  Columbus        NaT  \n",
      "996     0.00          China   Chengdu 2018-01-08  \n",
      "997     0.15  United States     Miami        NaT  \n",
      "998     0.00          China   Chengdu        NaT  \n",
      "999     0.31  United States     Miami        NaT  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(\"ESD.xlsx\")\n",
    "# print(data)\n",
    "# by default head and tail value is 5\n",
    "# print(data.head(10))    #shows 1st 10 data\n",
    "print(data.tail(10))    #shows last 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   EEID           1000 non-null   object        \n",
      " 1   Full Name      1000 non-null   object        \n",
      " 2   Job Title      1000 non-null   object        \n",
      " 3   Department     1000 non-null   object        \n",
      " 4   Business Unit  1000 non-null   object        \n",
      " 5   Gender         1000 non-null   object        \n",
      " 6   Ethnicity      1000 non-null   object        \n",
      " 7   Age            1000 non-null   int64         \n",
      " 8   Hire Date      1000 non-null   datetime64[ns]\n",
      " 9   Annual Salary  1000 non-null   int64         \n",
      " 10  Bonus %        1000 non-null   float64       \n",
      " 11  Country        1000 non-null   object        \n",
      " 12  City           1000 non-null   object        \n",
      " 13  Exit Date      85 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), int64(2), object(9)\n",
      "memory usage: 109.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info()) #gives data type , informations about dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Salary</th>\n",
       "      <th>Bonus %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.382000</td>\n",
       "      <td>113217.365000</td>\n",
       "      <td>0.088660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.246981</td>\n",
       "      <td>53545.985644</td>\n",
       "      <td>0.117856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>40063.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>71430.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>96557.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>150782.250000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>258498.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  Annual Salary      Bonus %\n",
       "count  1000.000000    1000.000000  1000.000000\n",
       "mean     44.382000  113217.365000     0.088660\n",
       "std      11.246981   53545.985644     0.117856\n",
       "min      25.000000   40063.000000     0.000000\n",
       "25%      35.000000   71430.250000     0.000000\n",
       "50%      45.000000   96557.000000     0.000000\n",
       "75%      54.000000  150782.250000     0.150000\n",
       "max      65.000000  258498.000000     0.400000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() #gives the numarical columns (which have integer/float values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEID               0\n",
      "Full Name          0\n",
      "Job Title          0\n",
      "Department         0\n",
      "Business Unit      0\n",
      "Gender             0\n",
      "Ethnicity          0\n",
      "Age                0\n",
      "Hire Date          0\n",
      "Annual Salary      0\n",
      "Bonus %            0\n",
      "Country            0\n",
      "City               0\n",
      "Exit Date        915\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#null values \n",
    "# print(data.isnull())\n",
    "#how many null values do we have\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handeling Duplicate values in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"company1.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#duplicate values must be present in unique rows(here EEID)\n",
    "print(data.duplicated(\"EEID\"))    #swhows duplicate values\n",
    "# print(data[\"EEID\"].duplicated().sum())  #shows no. of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n"
     ]
    }
   ],
   "source": [
    "print(data.drop_duplicates(\"EEID\"))   #delete duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with missing data / Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"company1.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEID      0\n",
      "Name      1\n",
      "gender    1\n",
      "salary    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID    Name gender   salary\n",
      "1  EMP02   rohit      M  25000.0\n",
      "3  EMP01  ayushi      F  20000.0\n",
      "6  EMP02   rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "# dropna deletes the entire row containg value null, it is problem\n",
    "print(data.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      hii\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    hii  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       hii      M  25000.0\n",
      "5  EMP06     rohit      M      hii\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# we can replace by any string or value but it makes no sense as age can't be any value or name salary can't be string\n",
    "print(data.replace(np.NaN,\"hii\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24400.0\n",
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n",
      "24400.0\n"
     ]
    }
   ],
   "source": [
    "#it is preffereable to drop null vallues individual\n",
    "#for salry we should replace null values with its original mean values , thus after droping the mean value remains same\n",
    "print(data[\"salary\"].mean())\n",
    "data[\"salary\"]=data[\"salary\"].replace(np.NaN,24400)\n",
    "print(data)\n",
    "print(data[\"salary\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  25000.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali      F  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05     rohit      M  25000.0\n",
      "5  EMP06     rohit      M  25000.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "#fills forward the previous value to its next nulll value\n",
    "# print(data.fillna(method = \"ffill\"))\n",
    "\n",
    "#fills backward the next value to its previous nulll value\n",
    "print(data.fillna(method = \"bfill\"))\n",
    "\n",
    "#fills all null values with whatever we write here\n",
    "# print(data.fillna(\"hiii\"))   #same as print(data.replace(np.nan,\"hii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Transformation Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary           sallii\n",
      "0  EMP01    ayushi      F      NaN              NaN\n",
      "1  EMP02     rohit      M  25000.0  income handsome\n",
      "2  EMP03  pranjali    NaN  27000.0     income prime\n",
      "3  EMP01    ayushi      F  20000.0              NaN\n",
      "4  EMP05       NaN      M  25000.0  income handsome\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"company1.csv\")\n",
    "# print(df)\n",
    "\n",
    "# creates a column and work on data\n",
    "df.loc[(df[\"salary\"] == 25000),\"sallii\"]=\"income handsome\"  #loc->lock \n",
    "df.loc[(df[\"salary\"] > 25000),\"sallii\"]=\"income prime\"\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary      info\n",
      "0  EMP01    ayushi      F      NaN  Ayushi F\n",
      "1  EMP02     rohit      M  25000.0   Rohit M\n",
      "2  EMP03  pranjali    NaN  27000.0       NaN\n",
      "3  EMP01    ayushi      F  20000.0  Ayushi F\n",
      "4  EMP05       NaN      M  25000.0       NaN\n",
      "5  EMP06     rohit      M      NaN   Rohit M\n",
      "6  EMP02     rohit      M  25000.0   Rohit M\n"
     ]
    }
   ],
   "source": [
    "# creates new column taking more than 1 column\n",
    "df[\"info\"] = df[\"Name\"].str.capitalize() + \" \" + df[\"gender\"]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Transformation Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender  salary\n",
      "0  EMP01    ayushi      F     NaN\n",
      "1  EMP02     rohit      M  5000.0\n",
      "2  EMP03  pranjali    NaN  5400.0\n",
      "3  EMP01    ayushi      F  4000.0\n",
      "4  EMP05       NaN      M  5000.0\n",
      "5  EMP06     rohit      M     NaN\n",
      "6  EMP02     rohit      M  5000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"company1.csv\")\n",
    "# print(df)\n",
    "\n",
    "#we can perform any mathematical operations\n",
    "df[\"salary\"]=(df[\"salary\"]/100)*20\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Months shorts\n",
      "0   January    Jan\n",
      "1  February    Feb\n",
      "2     March    Mar\n",
      "3     April    Apr\n",
      "4       May    May\n"
     ]
    }
   ],
   "source": [
    "data={\"Months\":[\"January\",\"February\",\"March\",\"April\",\"May\"]}\n",
    "a=pd.DataFrame(data)\n",
    "# print(a)\n",
    "\n",
    "# map function used to create new column and extracts the data we want\n",
    "def extract(value):\n",
    "    return value[0:3]\n",
    "a[\"shorts\"]=a[\"Months\"].map(extract)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas GroupBY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        EEID\n",
      "Department      Gender      \n",
      "Accounting      Female    53\n",
      "                Male      43\n",
      "Engineering     Female    80\n",
      "                Male      78\n",
      "Finance         Female    69\n",
      "                Male      51\n",
      "Human Resources Female    64\n",
      "                Male      61\n",
      "IT              Female   119\n",
      "                Male     122\n",
      "Marketing       Female    57\n",
      "                Male      63\n",
      "Sales           Female    76\n",
      "                Male      64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel(\"ESD.xlsx\")\n",
    "# number of employees group by department(1-level of group by)\n",
    "# gp = data.groupby(\"Department\").agg({\"EEID\":\"count\"})\n",
    "# number of employees group by department and gender (2-level of group by)\n",
    "gp = data.groupby([\"Department\",\"Gender\"]).agg({\"EEID\":\"count\"})\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Annual Salary  Age\n",
      "Country       Gender                    \n",
      "Brazil        Female         258426   25\n",
      "              Male           249506   26\n",
      "China         Female         249686   25\n",
      "              Male           257194   25\n",
      "United States Female         258498   25\n",
      "              Male           258081   25\n"
     ]
    }
   ],
   "source": [
    "# gp1=data.groupby(\"Country\").agg({\"Age\":\"mean\"})\n",
    "#max salary group by country\n",
    "\n",
    "# gp1=data.groupby(\"Country\").agg({\"Annual Salary\":\"max\"})\n",
    "#max salary,max age group by country,gender\n",
    "\n",
    "gp1=data.groupby([\"Country\",\"Gender\"]).agg({\"Annual Salary\":\"max\",\"Age\":\"min\"})\n",
    "print(gp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Merge , Join , Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names  Age\n",
      "0    E01     Ram   34\n",
      "1    E02   Shyam   56\n",
      "2    E03   Rahul   23\n",
      "3    E04  Vishal   44\n",
      "4    E05    Ravi   32\n",
      "5    E06    John   36\n",
      "\n",
      "  Emp Id  Salary\n",
      "0    E01   45000\n",
      "1    E02   56000\n",
      "2    E07   34000\n",
      "3    E04   30000\n",
      "4    E05   50000\n",
      "5    E08   36000\n"
     ]
    }
   ],
   "source": [
    "#Merge\n",
    "\n",
    "import pandas as pd\n",
    "data1 = {\"Emp Id\":[\"E01\",\"E02\",\"E03\",\"E04\",\"E05\",\"E06\"],\n",
    "         \"Names\":[\"Ram\",\"Shyam\",\"Rahul\",\"Vishal\",\"Ravi\",\"John\"],\n",
    "         \"Age\":[34,56,23,44,32,36]}\n",
    "data2 = {\"Emp Id\":[\"E01\",\"E02\",\"E07\",\"E04\",\"E05\",\"E08\"],\n",
    "         \"Salary\":[45000,56000,34000,30000,50000,36000]}\n",
    "df1=pd.DataFrame(data1)\n",
    "df2=pd.DataFrame(data2)\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names  Age  Salary\n",
      "0    E01     Ram   34   45000\n",
      "1    E02   Shyam   56   56000\n",
      "2    E04  Vishal   44   30000\n",
      "3    E05    Ravi   32   50000\n"
     ]
    }
   ],
   "source": [
    "#join on the basis of common data between tables\n",
    "print(pd.merge(df1,df2,on = \"Emp Id\")) #by default it has inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names  Age   Salary\n",
      "0    E01     Ram   34  45000.0\n",
      "1    E02   Shyam   56  56000.0\n",
      "2    E03   Rahul   23      NaN\n",
      "3    E04  Vishal   44  30000.0\n",
      "4    E05    Ravi   32  50000.0\n",
      "5    E06    John   36      NaN\n"
     ]
    }
   ],
   "source": [
    "#join on the basis of left table\n",
    "print(pd.merge(left=df1,right=df2,on = \"Emp Id\", how=\"left\")) #left outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names   Age  Salary\n",
      "0    E01     Ram  34.0   45000\n",
      "1    E02   Shyam  56.0   56000\n",
      "2    E07     NaN   NaN   34000\n",
      "3    E04  Vishal  44.0   30000\n",
      "4    E05    Ravi  32.0   50000\n",
      "5    E08     NaN   NaN   36000\n"
     ]
    }
   ],
   "source": [
    "#join on the basis of right table\n",
    "print(pd.merge(left=df1,right=df2,on = \"Emp Id\", how=\"right\")) #right outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\"Emp Id\":[\"E01\",\"E02\",\"E03\",\"E04\",\"E05\",\"E06\"],\n",
    "         \"Names\":[\"Ram\",\"Shyam\",\"Rahul\",\"Vishal\",\"Ravi\",\"John\"],\n",
    "         \"Age\":[34,56,23,44,32,36]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id      Names  Age\n",
      "0    E01        Ram   34\n",
      "1    E02      Shyam   56\n",
      "2    E03      Rahul   23\n",
      "3    E04     Vishal   44\n",
      "4    E05       Ravi   32\n",
      "5    E06       John   36\n",
      "0    E07  Prasenjit   34\n",
      "1    E08      Sumit   56\n",
      "2    E09      Rahul   23\n",
      "3    E10      Ankit   44\n",
      "4    E11      Sayan   32\n",
      "5    E12      Akash   36\n"
     ]
    }
   ],
   "source": [
    "#Concatenate\n",
    "\n",
    "data1 = {\"Emp Id\":[\"E01\",\"E02\",\"E03\",\"E04\",\"E05\",\"E06\"],\n",
    "         \"Names\":[\"Ram\",\"Shyam\",\"Rahul\",\"Vishal\",\"Ravi\",\"John\"],\n",
    "         \"Age\":[34,56,23,44,32,36]}\n",
    "data2 = {\"Emp Id\":[\"E07\",\"E08\",\"E09\",\"E10\",\"E11\",\"E12\"],\n",
    "         \"Names\":[\"Prasenjit\",\"Sumit\",\"Rahul\",\"Ankit\",\"Sayan\",\"Akash\"],\n",
    "         \"Age\":[34,56,23,44,32,36]}\n",
    "df1=pd.DataFrame(data1)\n",
    "df2=pd.DataFrame(data2)\n",
    "print(pd.concat([df1,df2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fruits  Price  Quantity\n",
      "0   Mango    120        10\n",
      "1  apples    200        15\n",
      "2  banana     80        20\n",
      "3  papaya    150         8\n",
      "   Fruits  Price  Quantity\n",
      "0   Mango     60        20\n",
      "1  apples    130        12\n",
      "2  banana     80        20\n",
      "3  papaya    100        15\n",
      "   Price        Quantity      \n",
      "    self  other     self other\n",
      "0  120.0   60.0     10.0  20.0\n",
      "1  200.0  130.0     15.0  12.0\n",
      "3  150.0  100.0      8.0  15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dict={\"Fruits\":[\"Mango\",\"apples\",\"banana\",\"papaya\"],\n",
    "      \"Price\":[120,200,80,150],\n",
    "      \"Quantity\":[10,15,20,8]}\n",
    "df1=pd.DataFrame(dict)\n",
    "print(df1)\n",
    "\n",
    "#copy df1 data into df2\n",
    "df2=df1.copy()\n",
    "# print(df2)\n",
    "df2.loc[0,\"Price\"]=60\n",
    "df2.loc[1,\"Price\"]=130\n",
    "df2.loc[3,\"Price\"]=100\n",
    "df2.loc[0,\"Quantity\"]=20\n",
    "df2.loc[1,\"Quantity\"]=12\n",
    "df2.loc[3,\"Quantity\"]=15\n",
    "print(df2)\n",
    "\n",
    "#to see the differece ,we use compare\n",
    "\n",
    "#shows only the datas which are alterded\n",
    "# print(df1.compare(df2))   #by default here axis=1\n",
    "# print(df1.compare(df2,align_axis=0))   \n",
    "\n",
    "#shows all the datas which are alterded as well as not altered\n",
    "# print(df1.compare(df2,keep_shape=True))  #NaN means no change\n",
    "print(df1.compare(df2,keep_shape=False))   # same as print(df1.compare(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoting , Melting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Keys  names Houses Grades\n",
      "0   k1   John    red    3rd\n",
      "1   k2    Ben   blue    8th\n",
      "2   k1  David  green    9th\n",
      "3   k2  Petre    red    8th\n",
      "      Houses                   Grades                 \n",
      "names    Ben  David John Petre    Ben David John Petre\n",
      "Keys                                                  \n",
      "k1       NaN  green  red   NaN    NaN   9th  3rd   NaN\n",
      "k2      blue    NaN  NaN   red    8th   NaN  NaN   8th\n"
     ]
    }
   ],
   "source": [
    "#Pivoting\n",
    "\n",
    "import pandas as pd\n",
    "dict={\"Keys\":[\"k1\",\"k2\",\"k1\",\"k2\"],\n",
    "      \"names\":[\"John\",\"Ben\",\"David\",\"Petre\"],\n",
    "      \"Houses\":[\"red\",\"blue\",\"green\",\"red\"],\n",
    "      \"Grades\":[\"3rd\",\"8th\",\"9th\",\"8th\"]}\n",
    "df=pd.DataFrame(dict)\n",
    "print(df)\n",
    "\n",
    "#pivot for single data\n",
    "# print(df.pivot(index=\"Keys\",columns=\"names\",values=\"Houses\"))   #(index,columns,values)\n",
    "#pivot for multiple data\n",
    "print(df.pivot(index=\"Keys\",columns=\"names\",values=[\"Houses\",\"Grades\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Names Houses Grades\n",
      "0   John    red    3rd\n",
      "1    Ben   blue    8th\n",
      "2  David  green    9th\n",
      "3  Petre    red    8th\n",
      "   Names Houses&Grades results\n",
      "0   John        Houses     red\n",
      "1    Ben        Houses    blue\n",
      "2  David        Houses   green\n",
      "3  Petre        Houses     red\n",
      "4   John        Grades     3rd\n",
      "5    Ben        Grades     8th\n",
      "6  David        Grades     9th\n",
      "7  Petre        Grades     8th\n"
     ]
    }
   ],
   "source": [
    "#Melting\n",
    "\n",
    "dict={\"Names\":[\"John\",\"Ben\",\"David\",\"Petre\"],\n",
    "      \"Houses\":[\"red\",\"blue\",\"green\",\"red\"],\n",
    "      \"Grades\":[\"3rd\",\"8th\",\"9th\",\"8th\"]}\n",
    "df=pd.DataFrame(dict)\n",
    "print(df)\n",
    "\n",
    "#convering columns as data and values\n",
    "\n",
    "#for single variables\n",
    "# print(pd.melt ( df, id_vars=[\"Names\"], value_vars=[\"Houses\"] ))   \n",
    "#for multiple variables\n",
    "# print(pd.melt ( df, id_vars=[\"Names\"], value_vars=[\"Houses\",\"Grades\"] ))\n",
    "\n",
    "#to rename the columns\n",
    "print(pd.melt ( df, id_vars=[\"Names\"], value_vars=[\"Houses\",\"Grades\"], var_name=\"Houses&Grades\", value_name=\"results\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
